{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogP optimization with ReLeaSE algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will optimized parameters of pretrained generative RNN to produce molecules with values of logP within drug-like region according to Lipinsky rule. We use policy gradient algorithm with custom reward function to bias the properties of generated molecules aka Reinforcement Learninf for Structural Evolution (ReLeaSE) as was proposed in **Popova, M., Isayev, O., & Tropsha, A. (2018). *Deep reinforcement learning for de novo drug design*. Science advances, 4(7), eaap7885.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./release/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "from rdkit import Chem, DataStructs\n",
    "from stackRNN import StackAugmentedRNN\n",
    "from data import GeneratorData \n",
    "from utils import canonical_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data for the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from CHEMBL: a collection of 1,576,904 SMILES. This data will be used to train the SMILES generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_path = './data/chembl_22_clean_1576904_sorted_std_final.smi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<', '>', '#', '%', ')', '(', '+', '-', '/', '.', '1', '0', '3', '2', '5', '4', '7',\n",
    "          '6', '9', '8', '=', 'A', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'P', 'S', '[', ']',\n",
    "          '\\\\', 'c', 'e', 'i', 'l', 'o', 'n', 'p', 's', 'r', '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = GeneratorData(training_data_path=gen_data_path, delimiter='\\t', \n",
    "                         cols_to_read=[0], keep_header=True, tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data.use_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**plot_hist** function plots histogram of predicted properties and a vertical line for thershold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_hist(prediction, n_to_generate):\n",
    "    prediction = np.array(prediction)\n",
    "    percentage_in_threshold = np.sum((prediction >= 0.0) & \n",
    "                                     (prediction <= 5.0))/len(prediction)\n",
    "    print(\"Percentage of predictions within drug-like region:\", percentage_in_threshold)\n",
    "    print(\"Proportion of valid SMILES:\", len(prediction)/n_to_generate)\n",
    "    ax = sns.kdeplot(prediction, shade=True)\n",
    "    plt.axvline(x=0.0)\n",
    "    plt.axvline(x=5.0)\n",
    "    ax.set(xlabel='Predicted LogP', \n",
    "           title='Distribution of predicted LogP for generated molecules')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**estimate_and_update** function:\n",
    "\n",
    "1) generates n_to_generate number of SMILES strings\n",
    "\n",
    "2) filters invalid SMILES\n",
    "\n",
    "3) predicts logP for valid SMILES\n",
    "\n",
    "4) plots histogram of predicted logP\n",
    "\n",
    "5) Returns valid SMILES and their predicted logPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def estimate_and_update(generator, predictor, n_to_generate):\n",
    "    generated = []\n",
    "    pbar = tqdm(range(n_to_generate))\n",
    "    for i in pbar:\n",
    "        pbar.set_description(\"Generating molecules...\")\n",
    "        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\n",
    "\n",
    "    sanitized = canonical_smiles(generated, sanitize=False, throw_warning=False)[:-1]\n",
    "    unique_smiles = list(np.unique(sanitized))[1:]\n",
    "    smiles, prediction, nan_smiles = predictor.predict(unique_smiles, use_tqdm=True)  \n",
    "                                                       \n",
    "    plot_hist(prediction, n_to_generate)\n",
    "        \n",
    "    return smiles, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing and training the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will used stack augmented generative GRU as a generator. The model was trained to predict the next symbol from SMILES alphabet using the already generated prefix. Model was trained to minimize the cross-entropy loss between predicted symbol and ground truth symbol. Scheme of the generator when inferring new SMILES is shown below:\n",
    "\n",
    "<img src=\"./figures/generator.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize stack-augmented generative RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1500\n",
    "stack_width = 1500\n",
    "stack_depth = 200\n",
    "layer_type = 'GRU'\n",
    "lr = 0.001\n",
    "optimizer_instance = torch.optim.Adadelta\n",
    "\n",
    "my_generator = StackAugmentedRNN(input_size=gen_data.n_characters, hidden_size=hidden_size,\n",
    "                                 output_size=gen_data.n_characters, layer_type=layer_type,\n",
    "                                 n_layers=1, is_bidirectional=False, has_stack=True,\n",
    "                                 stack_width=stack_width, stack_depth=stack_depth, \n",
    "                                 use_cuda=use_cuda, \n",
    "                                 optimizer_instance=optimizer_instance, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want train the model from scratch, uncomment the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './checkpoints/generator/checkpoint_biggest_rnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the SMILES generator, using the `gen_data` defined above. The training is set to 1,500,000 iterations (epochs) which, in my computer (Acer Predator Helios 300 with 1 NVIDIA GEFORCE GTX 1060, 6GB memory), takes ~5h 54min ( approx. 6h), to run only 3% (47,726) of the total of 1,500,000 iterations.\n",
    "\n",
    "For running all the iterations on my computer it would take ~12,000 minutes, or 200h. Just for testing purposes, I'll run for only 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c627a1b6e4a4aa7646a4e727f6b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training in progress...', max=10, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    #losses = my_generator.fit(gen_data, 1500000)\n",
    "    losses = my_generator.fit(gen_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22824684d68>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x0000022802485598>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gmseabra\\Miniconda3\\envs\\unc\\lib\\site-packages\\tqdm\\_tqdm.py\", line 966, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\gmseabra\\Miniconda3\\envs\\unc\\lib\\site-packages\\tqdm\\_tqdm_notebook.py\", line 239, in close\n",
      "    super(tqdm_notebook, self).close(*args, **kwargs)\n",
      "  File \"C:\\Users\\gmseabra\\Miniconda3\\envs\\unc\\lib\\site-packages\\tqdm\\_tqdm.py\", line 1158, in close\n",
      "    if self.disable:\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disable'\n"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_generator.evaluate(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_generator.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can skip the process of training and load the pretrained parameters into the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo we will use Recurrent Neural Network, i.e. unidirectional LSTM with 2 layers. The network is trained in 5-fold cross validation manner using the OpenChem toolkit (https://github.com/Mariewelt/OpenChem). In this demo we only upload the pretrained model. The training demo is in *RecurrentQSAR-example-logp.ipynb* file in the same directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'OpenChem'...\n"
     ]
    }
   ],
   "source": [
    "! git clone --single-branch --branch develop https://github.com/Mariewelt/OpenChem.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('./OpenChem/')\n",
    "sys.path.append('C:\\\\Users\\\\gmseabra\\\\OneDrive\\\\source\\\\repos\\\\ReLeaSE\\\\OpenChem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\gmseabra\\\\OneDrive\\\\source\\\\repos\\\\ReLeaSE',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc\\\\python37.zip',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc\\\\DLLs',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc\\\\lib',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc',\n",
       " '',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\Miniconda3\\\\envs\\\\unc\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\.ipython',\n",
       " './release/',\n",
       " 'C:\\\\Users\\\\gmseabra\\\\OneDrive\\\\source\\\\repos\\\\ReLeaSE\\\\OpenChem']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-5a172279ac26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrnn_predictor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRNNPredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\source\\repos\\ReLeaSE\\release\\rnn_predictor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./OpenChem/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSmiles2Label\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSmiles2Label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic_embedding\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_encoder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRNNEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\source\\repos\\ReLeaSE\\OpenChem\\openchem\\models\\Smiles2Label.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenchem_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenChemModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenchem_optimizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenChemOptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenchem_lr_scheduler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenChemLRScheduler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\source\\repos\\ReLeaSE\\OpenChem\\openchem\\models\\openchem_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime_since\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopenchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenchem_optimizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenChemOptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\source\\repos\\ReLeaSE\\OpenChem\\openchem\\utils\\logger.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Code referenced from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from rnn_predictor import RNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_tokens = tokens + [' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_params = './checkpoints/logP/model_parameters.pkl'\n",
    "path_to_checkpoint = './checkpoints/logP/fold_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictor = RNNPredictor(path_to_params, path_to_checkpoint, predictor_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we produce the unbiased distribution of the property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smiles_unbiased, prediction_unbiased = estimate_and_update(my_generator,\n",
    "                                                           my_predictor,\n",
    "                                                           n_to_generate=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biasing the distribution of the generator with reinforcement learning (policy gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine the generator and the predictor into a single pipeline. The generator produces new SMILES string, which is then evaluated by the predictor. Based on the obtain prediction and our goal, we assign a numerical reward value and update the parameters of the generator using policy gradient algorithm.\n",
    "\n",
    "<img src=\"./figures/rl_pipeline.png\">\n",
    "\n",
    "Policy gradient loss is defined as:\n",
    "$$\n",
    "L(S|\\theta) = -\\dfrac{1}{n}\\sum_{i=1}^{|S|} \\sum_{j=1}^{length(s_i)} R_i\\cdot \\gamma^i \\cdot \\log p(s_i|s_0 \\dots s_{i-1}\\theta),\n",
    "$$\n",
    "\n",
    "where $R_i$ is the reward obtained at time step $i$ $\\gamma$ is the discount factor and $p(s_i|s_0 \\dots s_{i-1}, \\theta)$ is the probability of the next character given the prefix, which we obtain from the generator. \n",
    "\n",
    "In our case the reward is the same for every time step and is equal to the reward for the whole molecule. Discount factor $\\gamma$ is a number close to $1.0$ (it could be $1.0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing logP to be in drug like region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reinforcement import Reinforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a copy of the generator that will be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator_max = StackAugmentedRNN(input_size=gen_data.n_characters, \n",
    "                                     hidden_size=hidden_size,\n",
    "                                     output_size=gen_data.n_characters, \n",
    "                                     layer_type=layer_type,\n",
    "                                     n_layers=1, is_bidirectional=False, has_stack=True,\n",
    "                                     stack_width=stack_width, stack_depth=stack_depth, \n",
    "                                     use_cuda=use_cuda, \n",
    "                                     optimizer_instance=optimizer_instance, lr=lr)\n",
    "\n",
    "my_generator_max.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up some parameters for the experiment\n",
    "n_to_generate = 200\n",
    "n_policy_replay = 10\n",
    "n_policy = 15\n",
    "n_iterations = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_moving_average(previous_values, new_value, ma_window_size=10):\n",
    "    value_ma = np.sum(previous_values[-(ma_window_size-1):]) + new_value\n",
    "    value_ma = value_ma/(len(previous_values[-(ma_window_size-1):]) + 1)\n",
    "    return value_ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reward function we will use here is the following:\n",
    "\n",
    "$$\n",
    "R =  \\begin{cases} 11.0, & \\mbox{if } 1.0 < \\log P < 4.0 \\\\ 1.0, & \\mbox{otherwise}  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_logp(smiles, predictor, invalid_reward=0.0):\n",
    "    mol, prop, nan_smiles = predictor.predict([smiles])\n",
    "    if len(nan_smiles) == 1:\n",
    "        return invalid_reward\n",
    "    if (prop[0] >= 1.0) and (prop[0] <= 4.0):\n",
    "        return 11.0\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 12)\n",
    "reward = lambda x: 11.0 if ((x > 1.0) and (x < 4.0)) else 1.0\n",
    "plt.plot(x, [reward(i) for i in x])\n",
    "plt.xlabel('logP value')\n",
    "plt.ylabel('Reward value')\n",
    "plt.title('Reward function for logP optimization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_logp = Reinforcement(my_generator_max, my_predictor, get_reward_logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "rl_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "    for j in trange(n_policy, desc='Policy gradient...'):\n",
    "        cur_reward, cur_loss = RL_logp.policy_gradient(gen_data)\n",
    "        rewards.append(simple_moving_average(rewards, cur_reward)) \n",
    "        rl_losses.append(simple_moving_average(rl_losses, cur_loss))\n",
    "    \n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Average reward')\n",
    "    plt.show()\n",
    "    plt.plot(rl_losses)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "        \n",
    "    smiles_cur, prediction_cur = estimate_and_update(RL_logp.generator, \n",
    "                                                     my_predictor, \n",
    "                                                     n_to_generate)\n",
    "    print('Sample trajectories:')\n",
    "    for sm in smiles_cur[:5]:\n",
    "        print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smiles_biased, prediction_biased = estimate_and_update(RL_logp.generator, \n",
    "                                                       my_predictor,\n",
    "                                                       n_to_generate=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(prediction_biased, label='Optimized', shade=True, color='purple')\n",
    "sns.kdeplot(prediction_unbiased, label='Unbiased', shade=True, color='grey')\n",
    "plt.xlabel('Predicted logP values')\n",
    "plt.title('Initial and biased distributions of log P')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing random molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will draw some random compounds from the biased library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import DrawingOptions\n",
    "from rdkit.Chem import Draw\n",
    "DrawingOptions.atomLabelFontSize = 50\n",
    "DrawingOptions.dotsPerAngstrom = 100\n",
    "DrawingOptions.bondLineWidth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_mols = [Chem.MolFromSmiles(sm, sanitize=True) for sm in smiles_biased]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_gen_mols = [generated_mols[i] for i in np.where(np.array(generated_mols) != None)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_draw = 20\n",
    "ind = np.random.randint(0, len(sanitized_gen_mols), n_to_draw)\n",
    "mols_to_draw = [sanitized_gen_mols[i] for i in ind]\n",
    "legends = ['log P = ' + str(prediction_biased[i]) for i in ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Draw.MolsToGridImage(mols_to_draw, molsPerRow=5, \n",
    "                     subImgSize=(200,200), legends=legends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "UNC-ML (Python 3.7.1)",
   "language": "python",
   "name": "unc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
